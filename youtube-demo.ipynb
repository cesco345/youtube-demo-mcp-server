{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e6a259-e863-4a0f-831e-6835652e1d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create Conda Environment\n",
    "echo \"Creating conda environment...\"\n",
    "conda create -n youtube-analyzer python=3.11 -y\n",
    "conda activate youtube-analyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea873348-a63e-4699-a5d7-936e1d2621f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create Project Directory Structure\n",
    "echo \"Setting up project structure...\"\n",
    "mkdir -p youtube-demo-mcp-server/{models,server,services,tools,deployment/firebase,output,old_scripts}\n",
    "cd youtube-demo-mcp-server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efc2b94-14da-4418-ab1f-4a3abc919cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Initialize Python Package Structure\n",
    "touch models/__init__.py\n",
    "touch server/__init__.py\n",
    "touch services/__init__.py\n",
    "touch tools/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca7c6cb-67ae-450a-92a0-dc3f493897cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Install Core Dependencies\n",
    "echo \"Installing dependencies...\"\n",
    "pip install mcp>=0.9.0\n",
    "pip install google-api-python-client\n",
    "pip install pandas numpy\n",
    "pip install nltk textblob\n",
    "pip install matplotlib seaborn plotly\n",
    "pip install anthropic\n",
    "pip install fastapi uvicorn\n",
    "pip install firebase-admin\n",
    "pip install python-dotenv\n",
    "pip install pydantic\n",
    "pip install aiofiles\n",
    "*pip install jupyter notebook jupyterlab ipywidgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2525c437-3756-4bda-9966-9fd1a0913b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Download NLTK Data\n",
    "echo \"Downloading NLTK data...\"\n",
    "python -c \"import nltk; nltk.download('punkt')\"\n",
    "python -c \"import nltk; nltk.download('vader_lexicon')\"\n",
    "python -c \"import nltk; nltk.download('stopwords')\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962744b4-df60-4036-84db-e753dae35994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for example we will be using it in one of our tools:  market analysis tool\n",
    "from textblob import TextBlob\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# Analyze video title sentiment\n",
    "analyzer = SentimentIntensityAnalyzer()  # Uses vader_lexicon\n",
    "sentiment = analyzer.polarity_scores(\"Amazing Python Tutorial!\")\n",
    "\n",
    "# Split description into sentences\n",
    "sentences = sent_tokenize(description)  # Uses punkt\n",
    "\n",
    "# Filter out common words\n",
    "stop_words = set(stopwords.words('english'))  # Uses stopwords\n",
    "filtered_words = [word for word in words if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592232ac-9ddf-462b-b57c-306b77e4af4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Create Requirements File\n",
    "cat > requirements.txt << 'EOF'\n",
    "mcp>=0.9.0\n",
    "google-api-python-client==2.108.0\n",
    "pandas==2.1.3\n",
    "numpy==1.24.3\n",
    "nltk==3.8.1\n",
    "textblob==0.17.1\n",
    "matplotlib==3.7.2\n",
    "seaborn==0.12.2\n",
    "plotly==5.17.0\n",
    "anthropic==0.7.7\n",
    "fastapi==0.104.1\n",
    "uvicorn==0.24.0\n",
    "firebase-admin==6.2.0\n",
    "python-dotenv==1.0.0\n",
    "pydantic==2.5.0\n",
    "aiofiles==23.2.1\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f4932a-aecf-4e17-9e9b-d48ce8bb2a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.py - System Configuration\n",
    "# Configuration & API Setup\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "class Config:\n",
    "    \"\"\"System-wide configuration settings\"\"\"\n",
    "    \n",
    "    # YouTube API Configuration\n",
    "    YOUTUBE_API_KEY = os.getenv('YOUTUBE_API_KEY')\n",
    "    YOUTUBE_API_SERVICE_NAME = 'youtube'\n",
    "    YOUTUBE_API_VERSION = 'v3'\n",
    "    \n",
    "    # Firebase Configuration\n",
    "    FIREBASE_PROJECT_ID = os.getenv('FIREBASE_PROJECT_ID')\n",
    "    FIREBASE_CREDENTIALS_PATH = os.getenv('FIREBASE_CREDENTIALS_PATH', 'deployment/firebase/credentials.json')\n",
    "    \n",
    "    # Claude AI Configuration\n",
    "    ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY')\n",
    "    CLAUDE_MODEL = 'claude-3-sonnet-20240229'\n",
    "    \n",
    "    # Analysis Parameters\n",
    "    MAX_VIDEOS_PER_SEARCH = 50\n",
    "    DEFAULT_REGION_CODE = 'US'\n",
    "    DEFAULT_LANGUAGE = 'en'\n",
    "    \n",
    "    # Scoring Weights\n",
    "    SENTIMENT_WEIGHT = 0.3\n",
    "    ENGAGEMENT_WEIGHT = 0.4\n",
    "    CREDIBILITY_WEIGHT = 0.3\n",
    "    \n",
    "    # Directory Configuration\n",
    "    PROJECT_ROOT = Path(__file__).parent\n",
    "    OUTPUT_DIR = PROJECT_ROOT / 'output'\n",
    "    MODELS_DIR = PROJECT_ROOT / 'models'\n",
    "    \n",
    "    # MCP Server Configuration\n",
    "    MCP_SERVER_NAME = 'youtube-intelligence'\n",
    "    MCP_SERVER_VERSION = '1.0.0'\n",
    "    MCP_SERVER_PORT = 8000\n",
    "    \n",
    "    # Rate Limiting\n",
    "    API_RATE_LIMIT = 100  # requests per minute\n",
    "    \n",
    "    @classmethod\n",
    "    def validate_config(cls):\n",
    "        \"\"\"Validate that required configuration is present\"\"\"\n",
    "        required_vars = [\n",
    "            'YOUTUBE_API_KEY',\n",
    "            'FIREBASE_PROJECT_ID',\n",
    "            'ANTHROPIC_API_KEY'\n",
    "        ]\n",
    "        \n",
    "        missing_vars = []\n",
    "        for var in required_vars:\n",
    "            if not getattr(cls, var):\n",
    "                missing_vars.append(var)\n",
    "        \n",
    "        if missing_vars:\n",
    "            raise ValueError(f\"Missing required environment variables: {', '.join(missing_vars)}\")\n",
    "        \n",
    "        return True\n",
    "\n",
    "# .env template file\n",
    "ENV_TEMPLATE = \"\"\"\n",
    "# YouTube Intelligence MCP Server - Environment Configuration\n",
    "# Episode 3: Configuration & API Setup\n",
    "\n",
    "# YouTube Data API\n",
    "YOUTUBE_API_KEY=your_youtube_api_key_here\n",
    "\n",
    "# Firebase Configuration\n",
    "FIREBASE_PROJECT_ID=your_firebase_project_id\n",
    "FIREBASE_CREDENTIALS_PATH=deployment/firebase/credentials.json\n",
    "\n",
    "# Claude AI API\n",
    "ANTHROPIC_API_KEY=your_anthropic_api_key_here\n",
    "\n",
    "# Optional: Custom Settings\n",
    "MAX_VIDEOS_PER_SEARCH=50\n",
    "DEFAULT_REGION_CODE=US\n",
    "DEFAULT_LANGUAGE=en\n",
    "\"\"\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create .env file if it doesn't exist\n",
    "    if not os.path.exists('.env'):\n",
    "        with open('.env', 'w') as f:\n",
    "            f.write(ENV_TEMPLATE)\n",
    "        print(\"Created .env template file. Please fill in your API keys.\")\n",
    "    else:\n",
    "        print(\"Configuration file already exists.\")\n",
    "    \n",
    "    # Validate configuration\n",
    "    try:\n",
    "        Config.validate_config()\n",
    "        print(\"Configuration validated successfully!\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Configuration error: {e}\")\n",
    "        print(\"Please check your .env file and add missing API keys.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45921d42-78bd-46e7-b001-a286ba7945ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models/youtube_models.py - YouTube Data Structures\n",
    "# Data Models & Architecture\n",
    "from typing import List, Optional, Dict, Any\n",
    "from pydantic import BaseModel, Field\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "class VideoCategory(str, Enum):\n",
    "    \"\"\"YouTube video categories\"\"\"\n",
    "    EDUCATION = \"education\"\n",
    "    ENTERTAINMENT = \"entertainment\"\n",
    "    TECHNOLOGY = \"technology\"\n",
    "    GAMING = \"gaming\"\n",
    "    MUSIC = \"music\"\n",
    "    NEWS = \"news\"\n",
    "    SPORTS = \"sports\"\n",
    "    OTHER = \"other\"\n",
    "\n",
    "\n",
    "class VideoStats(BaseModel):\n",
    "    \"\"\"Video statistics and metrics\"\"\"\n",
    "    view_count: int = 0\n",
    "    like_count: int = 0\n",
    "    comment_count: int = 0\n",
    "    duration_seconds: int = 0\n",
    "\n",
    "    @property\n",
    "    def engagement_rate(self) -> float:\n",
    "        \"\"\"Calculate engagement rate (likes + comments) / views\"\"\"\n",
    "        if self.view_count == 0:\n",
    "            return 0.0\n",
    "        return (self.like_count + self.comment_count) / self.view_count\n",
    "\n",
    "\n",
    "class VideoData(BaseModel):\n",
    "    \"\"\"Complete video data structure\"\"\"\n",
    "    video_id: str\n",
    "    title: str\n",
    "    description: str\n",
    "    channel_id: str\n",
    "    channel_title: str\n",
    "    published_at: datetime\n",
    "    duration: str\n",
    "    category: VideoCategory = VideoCategory.OTHER\n",
    "    stats: VideoStats\n",
    "    tags: List[str] = []\n",
    "    thumbnail_url: Optional[str] = None\n",
    "\n",
    "    # Analysis fields\n",
    "    sentiment_score: Optional[float] = None\n",
    "    credibility_score: Optional[float] = None\n",
    "    trending_score: Optional[float] = None\n",
    "\n",
    "    class Config:\n",
    "        json_encoders = {\n",
    "            datetime: lambda v: v.isoformat()\n",
    "        }\n",
    "\n",
    "\n",
    "class ChannelData(BaseModel):\n",
    "    \"\"\"YouTube channel information\"\"\"\n",
    "    channel_id: str\n",
    "    title: str\n",
    "    description: str\n",
    "    subscriber_count: int = 0\n",
    "    video_count: int = 0\n",
    "    view_count: int = 0\n",
    "    created_at: Optional[datetime] = None\n",
    "    thumbnail_url: Optional[str] = None\n",
    "\n",
    "    # Analysis fields\n",
    "    authority_score: Optional[float] = None\n",
    "    consistency_score: Optional[float] = None\n",
    "\n",
    "\n",
    "class SearchQuery(BaseModel):\n",
    "    \"\"\"YouTube search query parameters\"\"\"\n",
    "    query: str\n",
    "    max_results: int = 25\n",
    "    region_code: str = \"US\"\n",
    "    language: str = \"en\"\n",
    "    published_after: Optional[datetime] = None\n",
    "    published_before: Optional[datetime] = None\n",
    "    order: str = \"relevance\"  # relevance, date, rating, viewCount\n",
    "\n",
    "\n",
    "class SearchResult(BaseModel):\n",
    "    \"\"\"YouTube search results\"\"\"\n",
    "    query: SearchQuery\n",
    "    videos: List[VideoData]\n",
    "    total_results: int\n",
    "    search_time: datetime = Field(default_factory=datetime.now)\n",
    "\n",
    "    @property\n",
    "    def average_engagement(self) -> float:\n",
    "        \"\"\"Calculate average engagement rate across all videos\"\"\"\n",
    "        if not self.videos:\n",
    "            return 0.0\n",
    "        return sum(video.stats.engagement_rate for video in self.videos) / len(self.videos)\n",
    "\n",
    "\n",
    "class MarketTrend(BaseModel):\n",
    "    \"\"\"Market trend analysis data\"\"\"\n",
    "    keyword: str\n",
    "    trend_score: float\n",
    "    growth_rate: float\n",
    "    competition_level: str  # low, medium, high\n",
    "    related_topics: List[str] = []\n",
    "    analysis_date: datetime = Field(default_factory=datetime.now)\n",
    "\n",
    "\n",
    "class MarketAnalysis(BaseModel):\n",
    "    \"\"\"Complete market analysis results\"\"\"\n",
    "    query: str\n",
    "    trends: List[MarketTrend]\n",
    "    top_performers: List[VideoData]\n",
    "    market_insights: Dict[str, Any] = {}\n",
    "    analysis_summary: str = \"\"\n",
    "    created_at: datetime = Field(default_factory=datetime.now)\n",
    "\n",
    "\n",
    "# Example usage and validation\n",
    "if __name__ == \"__main__\":\n",
    "    # Create sample video data\n",
    "    sample_video = VideoData(\n",
    "        video_id=\"sample123\",\n",
    "        title=\"How to Build YouTube Intelligence AI\",\n",
    "        description=\"A comprehensive tutorial on building AI systems\",\n",
    "        channel_id=\"channel123\",\n",
    "        channel_title=\"Tech Tutorials\",\n",
    "        published_at=datetime.now(),\n",
    "        duration=\"PT15M30S\",\n",
    "        category=VideoCategory.EDUCATION,\n",
    "        stats=VideoStats(\n",
    "            view_count=10000,\n",
    "            like_count=500,\n",
    "            comment_count=100,\n",
    "            duration_seconds=930\n",
    "        ),\n",
    "        tags=[\"AI\", \"YouTube\", \"Tutorial\", \"Programming\"]\n",
    "    )\n",
    "\n",
    "    print(\"Sample Video Data:\")\n",
    "    print(f\"Title: {sample_video.title}\")\n",
    "    print(f\"Engagement Rate: {sample_video.stats.engagement_rate:.2%}\")\n",
    "    print(f\"JSON: {sample_video.json(indent=2)}\")\n",
    "\n",
    "    # Validate model\n",
    "    print(\"\\nVideo data model validation successful!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d0a056-b5d7-45c7-8461-90d0a5e9b2e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44866c5b-c1a4-4c54-87bc-fa19d6416aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#video 4 - mcp inspector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bed74d-e048-4b83-bb6e-5b2280afc617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# server/__main__.py - MCP Inspector Entry Point\n",
    "\n",
    "from mcp_server import main\n",
    "import sys\n",
    "import asyncio\n",
    "from pathlib import Path\n",
    "\n",
    "# this adds a project root to Python path\n",
    "project_root = Path(__file__).parent.parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4990a86-5a3f-49ee-9057-383d9098ce1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5b3dba-5457-487a-a824-c3c698a928c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mcp_server.py - Main MCP Server Implementation\n",
    "# MCP Server Implementation\n",
    "\n",
    "import asyncio\n",
    "import logging\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "# Correct imports for MCP Server\n",
    "from mcp.server import Server\n",
    "from mcp.server.models import InitializationOptions\n",
    "from mcp.server.stdio import stdio_server\n",
    "from mcp import ServerCapabilities, ToolsCapability\n",
    "from mcp.types import (\n",
    "    CallToolResult,\n",
    "    ListToolsResult,\n",
    "    TextContent,\n",
    "    Tool,\n",
    ")\n",
    "\n",
    "from config import Config\n",
    "from tools.video_search_tool import VideoSearchTool\n",
    "from tools.market_analysis_tool import MarketAnalysisTool\n",
    "from tools.system_status_tool import SystemStatusTool\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Create the MCP server\n",
    "server = Server(Config.MCP_SERVER_NAME, Config.MCP_SERVER_VERSION)\n",
    "\n",
    "# Initialize tools\n",
    "youtube_tools = {\n",
    "    'search_videos': VideoSearchTool(),\n",
    "    'analyze_market': MarketAnalysisTool(),\n",
    "    'system_status': SystemStatusTool()\n",
    "}\n",
    "\n",
    "logger.info(f\"Initialized {len(youtube_tools)} MCP tools\")\n",
    "\n",
    "\n",
    "@server.list_tools()\n",
    "async def list_tools() -> List[Tool]:\n",
    "    \"\"\"List available MCP tools\"\"\"\n",
    "    try:\n",
    "        tools_list = []\n",
    "        for tool_name, tool_instance in youtube_tools.items():\n",
    "            mcp_tool = Tool(\n",
    "                name=tool_instance.name,\n",
    "                description=tool_instance.description,\n",
    "                inputSchema=tool_instance.inputSchema\n",
    "            )\n",
    "            tools_list.append(mcp_tool)\n",
    "\n",
    "        logger.info(f\"Listed {len(tools_list)} available tools\")\n",
    "        return tools_list\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error listing tools: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "@server.call_tool()\n",
    "async def call_tool(name: str, arguments: Dict[str, Any]) -> List[TextContent]:\n",
    "    \"\"\"Execute MCP tool calls\"\"\"\n",
    "    try:\n",
    "        logger.info(f\"Tool call: {name} with arguments: {arguments}\")\n",
    "\n",
    "        # Find and execute tool\n",
    "        if name not in youtube_tools:\n",
    "            error_msg = f\"Tool '{name}' not found. Available tools: {list(youtube_tools.keys())}\"\n",
    "            logger.error(error_msg)\n",
    "            return [TextContent(\n",
    "                type=\"text\",\n",
    "                text=f\"Error: {error_msg}\"\n",
    "            )]\n",
    "\n",
    "        # Execute tool\n",
    "        tool_instance = youtube_tools[name]\n",
    "        result = await tool_instance.call(arguments)\n",
    "\n",
    "        # Format response\n",
    "        if result.get('success', False):\n",
    "            response_text = format_tool_response(name, result)\n",
    "        else:\n",
    "            response_text = f\"Tool execution failed: {result.get('message', 'Unknown error')}\"\n",
    "\n",
    "        return [TextContent(type=\"text\", text=response_text)]\n",
    "\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error executing tool '{name}': {str(e)}\"\n",
    "        logger.error(error_msg)\n",
    "        return [TextContent(type=\"text\", text=error_msg)]\n",
    "\n",
    "\n",
    "def format_tool_response(tool_name: str, result: Dict[str, Any]) -> str:\n",
    "    \"\"\"Format tool response for display\"\"\"\n",
    "    try:\n",
    "        if tool_name == 'search_videos':\n",
    "            return format_video_search_response(result)\n",
    "        elif tool_name == 'analyze_market':\n",
    "            return format_market_analysis_response(result)\n",
    "        elif tool_name == 'system_status':\n",
    "            return format_system_status_response(result)\n",
    "        else:\n",
    "            return f\"Results from {tool_name}:\\n{str(result)}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error formatting response: {e}\")\n",
    "        return f\"Tool executed successfully but response formatting failed: {str(result)}\"\n",
    "\n",
    "\n",
    "def format_video_search_response(result: Dict[str, Any]) -> str:\n",
    "    \"\"\"Format video search results\"\"\"\n",
    "    response = []\n",
    "    response.append(f\"🔍 **YouTube Video Search Results**\")\n",
    "    response.append(f\"Query: {result.get('query', 'Unknown')}\")\n",
    "    response.append(f\"Found: {result.get('videos_found', 0)} videos\")\n",
    "    response.append(\n",
    "        f\"Average Engagement: {result.get('average_engagement', 'N/A')}\")\n",
    "    response.append(\"\")\n",
    "\n",
    "    videos = result.get('videos', [])\n",
    "    for i, video in enumerate(videos[:10], 1):  # Show top 10\n",
    "        response.append(f\"{i}. **{video['title']}**\")\n",
    "        response.append(f\"   Channel: {video['channel']}\")\n",
    "        response.append(\n",
    "            f\"   Views: {video['views']:,} | Likes: {video['likes']:,} | Comments: {video['comments']:,}\")\n",
    "        response.append(\n",
    "            f\"   Engagement: {video['engagement_rate']} | Published: {video['published']}\")\n",
    "        response.append(\n",
    "            f\"   Duration: {video['duration']} | Category: {video['category']}\")\n",
    "        response.append(f\"   URL: {video['url']}\")\n",
    "        response.append(\"\")\n",
    "\n",
    "    return \"\\n\".join(response)\n",
    "\n",
    "\n",
    "def format_market_analysis_response(result: Dict[str, Any]) -> str:\n",
    "    \"\"\"Format market analysis results\"\"\"\n",
    "    response = []\n",
    "    response.append(f\"📊 **Market Analysis Results**\")\n",
    "    response.append(f\"Topic: {result.get('topic', 'Unknown')}\")\n",
    "    response.append(f\"Videos Analyzed: {result.get('videos_analyzed', 0)}\")\n",
    "    response.append(f\"Timeframe: {result.get('timeframe_days', 0)} days\")\n",
    "    response.append(\"\")\n",
    "\n",
    "    analysis = result.get('analysis', {})\n",
    "\n",
    "    # Market Overview\n",
    "    overview = analysis.get('market_overview', {})\n",
    "    response.append(\"**📈 Market Overview**\")\n",
    "    response.append(f\"• Total Views: {overview.get('total_views', 0):,}\")\n",
    "    response.append(f\"• Average Views: {overview.get('average_views', 0):,}\")\n",
    "    response.append(\n",
    "        f\"• Average Engagement: {overview.get('average_engagement_rate', 'N/A')}\")\n",
    "    response.append(f\"• Unique Creators: {overview.get('unique_creators', 0)}\")\n",
    "    response.append(\n",
    "        f\"• Competition Level: {overview.get('competition_level', 'Unknown')}\")\n",
    "    response.append(\n",
    "        f\"• Market Sentiment: {overview.get('market_sentiment', 'N/A')}\")\n",
    "    response.append(\"\")\n",
    "\n",
    "    # Top Videos\n",
    "    top_videos = analysis.get('top_performing_videos', [])\n",
    "    if top_videos:\n",
    "        response.append(\"**🏆 Top Performing Videos**\")\n",
    "        for i, video in enumerate(top_videos[:5], 1):\n",
    "            response.append(\n",
    "                f\"{i}. {video['title']} - {video['views']:,} views ({video['channel']})\")\n",
    "        response.append(\"\")\n",
    "\n",
    "    # Top Channels\n",
    "    top_channels = analysis.get('top_channels', [])\n",
    "    if top_channels:\n",
    "        response.append(\"**🌟 Top Channels**\")\n",
    "        for i, channel in enumerate(top_channels[:5], 1):\n",
    "            response.append(\n",
    "                f\"{i}. {channel['channel']} - {channel['total_views']:,} total views ({channel['video_count']} videos)\")\n",
    "        response.append(\"\")\n",
    "\n",
    "    # Insights\n",
    "    insights = analysis.get('insights', [])\n",
    "    if insights:\n",
    "        response.append(\"**💡 Key Insights**\")\n",
    "        for insight in insights:\n",
    "            response.append(f\"• {insight}\")\n",
    "\n",
    "    return \"\\n\".join(response)\n",
    "\n",
    "\n",
    "def format_system_status_response(result: Dict[str, Any]) -> str:\n",
    "    \"\"\"Format system status results\"\"\"\n",
    "    response = []\n",
    "    status = result.get('status', {})\n",
    "\n",
    "    response.append(\n",
    "        f\"⚡ **{status.get('server_name', 'YouTube Intelligence')} System Status**\")\n",
    "    response.append(f\"Version: {status.get('version', 'Unknown')}\")\n",
    "    response.append(f\"Status: {status.get('status', 'Unknown')}\")\n",
    "    response.append(f\"Timestamp: {status.get('timestamp', 'Unknown')}\")\n",
    "    response.append(\"\")\n",
    "\n",
    "    # Configuration\n",
    "    config = status.get('configuration', {})\n",
    "    response.append(\"**🔧 Configuration**\")\n",
    "    response.append(\n",
    "        f\"• YouTube API: {'✅ Configured' if config.get('youtube_api_configured') else '❌ Not Configured'}\")\n",
    "    response.append(\n",
    "        f\"• Firebase: {'✅ Configured' if config.get('firebase_configured') else '❌ Not Configured'}\")\n",
    "    response.append(\n",
    "        f\"• Claude API: {'✅ Configured' if config.get('claude_api_configured') else '❌ Not Configured'}\")\n",
    "    response.append(\n",
    "        f\"• Max Videos Per Search: {config.get('max_videos_per_search', 'Unknown')}\")\n",
    "    response.append(\"\")\n",
    "\n",
    "    # System Metrics (if available)\n",
    "    metrics = status.get('system_metrics', {})\n",
    "    if metrics and 'error' not in metrics:\n",
    "        response.append(\"**📊 System Metrics**\")\n",
    "        response.append(\n",
    "            f\"• CPU Usage: {metrics.get('cpu_percent', 'Unknown')}%\")\n",
    "        response.append(\n",
    "            f\"• Memory Usage: {metrics.get('memory_percent', 'Unknown')}%\")\n",
    "        response.append(\n",
    "            f\"• Disk Usage: {metrics.get('disk_usage_percent', 'Unknown')}%\")\n",
    "\n",
    "    return \"\\n\".join(response)\n",
    "\n",
    "\n",
    "async def main():\n",
    "    \"\"\"Main entry point for the MCP server\"\"\"\n",
    "    try:\n",
    "        logger.info(\"Starting YouTube Intelligence MCP Server\")\n",
    "\n",
    "        # Validate configuration\n",
    "        Config.validate_config()\n",
    "        logger.info(\"Configuration validated successfully\")\n",
    "\n",
    "        # Create server capabilities\n",
    "        capabilities = ServerCapabilities(tools=ToolsCapability())\n",
    "\n",
    "        # Create initialization options\n",
    "        init_options = InitializationOptions(\n",
    "            server_name=Config.MCP_SERVER_NAME,\n",
    "            server_version=Config.MCP_SERVER_VERSION,\n",
    "            capabilities=capabilities\n",
    "        )\n",
    "\n",
    "        # Run stdio server\n",
    "        async with stdio_server() as (read_stream, write_stream):\n",
    "            await server.run(read_stream, write_stream, init_options)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        logger.info(\"Server shutdown requested\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Server failed to start: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227f493e-e24f-48d9-a695-c6ab517ca7ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ada61b7-4b44-48a2-97f6-6e061c14fb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tools/system_status_tool.py - System Status Tool\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import psutil\n",
    "from typing import Any, Dict\n",
    "from datetime import datetime\n",
    "from mcp import Tool\n",
    "\n",
    "from config import Config\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class SystemStatusTool(Tool):\n",
    "    \"\"\"MCP tool for system status and health monitoring\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"system_status\",\n",
    "            description=\"Get YouTube Intelligence MCP Server system status and health metrics\",\n",
    "            inputSchema={\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"include_detailed\": {\n",
    "                        \"type\": \"boolean\",\n",
    "                        \"description\": \"Include detailed system metrics\",\n",
    "                        \"default\": False\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "\n",
    "    async def call(self, arguments: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Get system status\"\"\"\n",
    "        try:\n",
    "            include_detailed = arguments.get(\"include_detailed\", False)\n",
    "\n",
    "            # Basic system info\n",
    "            status = {\n",
    "                \"server_name\": Config.MCP_SERVER_NAME,\n",
    "                \"version\": Config.MCP_SERVER_VERSION,\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"status\": \"healthy\",\n",
    "                \"uptime_seconds\": self._get_uptime(),\n",
    "                \"configuration\": {\n",
    "                    \"youtube_api_configured\": bool(Config.YOUTUBE_API_KEY),\n",
    "                    \"firebase_configured\": bool(Config.FIREBASE_PROJECT_ID),\n",
    "                    \"claude_api_configured\": bool(Config.ANTHROPIC_API_KEY),\n",
    "                    \"output_directory\": str(Config.OUTPUT_DIR),\n",
    "                    \"max_videos_per_search\": Config.MAX_VIDEOS_PER_SEARCH\n",
    "                }\n",
    "            }\n",
    "\n",
    "            # Add detailed metrics if requested\n",
    "            if include_detailed:\n",
    "                status[\"system_metrics\"] = self._get_system_metrics()\n",
    "                status[\"api_status\"] = self._check_api_status()\n",
    "\n",
    "            return {\n",
    "                \"success\": True,\n",
    "                \"status\": status\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"System status error: {e}\")\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": str(e),\n",
    "                \"message\": \"Failed to get system status\"\n",
    "            }\n",
    "\n",
    "    def _get_uptime(self) -> float:\n",
    "        \"\"\"Get system uptime in seconds\"\"\"\n",
    "        try:\n",
    "            return psutil.boot_time()\n",
    "        except:\n",
    "            return 0.0\n",
    "\n",
    "    def _get_system_metrics(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get detailed system metrics\"\"\"\n",
    "        try:\n",
    "            return {\n",
    "                \"cpu_percent\": psutil.cpu_percent(interval=1),\n",
    "                \"memory_percent\": psutil.virtual_memory().percent,\n",
    "                \"disk_usage_percent\": psutil.disk_usage('/').percent,\n",
    "                \"process_count\": len(psutil.pids()),\n",
    "                \"network_connections\": len(psutil.net_connections())\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error getting system metrics: {e}\")\n",
    "            return {\"error\": \"Unable to retrieve system metrics\"}\n",
    "\n",
    "    def _check_api_status(self) -> Dict[str, str]:\n",
    "        \"\"\"Check API configuration status\"\"\"\n",
    "        return {\n",
    "            \"youtube_api\": \"configured\" if Config.YOUTUBE_API_KEY else \"not_configured\",\n",
    "            \"firebase\": \"configured\" if Config.FIREBASE_PROJECT_ID else \"not_configured\",\n",
    "            \"claude_api\": \"configured\" if Config.ANTHROPIC_API_KEY else \"not_configured\"\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf585d51-4c3a-466c-a1ef-630bc05bf509",
   "metadata": {},
   "outputs": [],
   "source": [
    "DANGEROUSLY_OMIT_AUTH=true npx @modelcontextprotocol/inspector python mcp_server.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907c135c-00e2-4e8d-a8c8-71afc3727bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38aef6d9-6cbf-4821-9b5b-141d7e38b420",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db95f1b0-c21d-4d9d-b760-d40bf50d6ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "video #5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47febdae-9c9d-492c-a4a2-270b747255f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# services/youtube_service.py - YouTube API Integration\n",
    "# YouTube Service Integration\n",
    "\n",
    "import logging\n",
    "from typing import List, Optional, Dict, Any\n",
    "from datetime import datetime, timedelta\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "import isodate\n",
    "\n",
    "from config import Config\n",
    "from models.youtube_models import VideoData, ChannelData, SearchQuery, SearchResult, VideoStats, VideoCategory\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class YouTubeService:\n",
    "    \"\"\"YouTube Data API service for video and channel operations\"\"\"\n",
    "\n",
    "    def __init__(self, api_key: str = None):\n",
    "        self.api_key = api_key or Config.YOUTUBE_API_KEY\n",
    "        if not self.api_key:\n",
    "            raise ValueError(\"YouTube API key is required\")\n",
    "\n",
    "        self.youtube = build(\n",
    "            Config.YOUTUBE_API_SERVICE_NAME,\n",
    "            Config.YOUTUBE_API_VERSION,\n",
    "            developerKey=self.api_key\n",
    "        )\n",
    "\n",
    "        logger.info(\"YouTube service initialized successfully\")\n",
    "\n",
    "    def search_videos(self, query: SearchQuery) -> SearchResult:\n",
    "        \"\"\"Search for videos using YouTube Data API\"\"\"\n",
    "        try:\n",
    "            logger.info(f\"Searching videos for query: {query.query}\")\n",
    "\n",
    "            # Build search parameters\n",
    "            search_params = {\n",
    "                'part': 'snippet',\n",
    "                'q': query.query,\n",
    "                'type': 'video',\n",
    "                'maxResults': min(query.max_results, 50),  # API limit\n",
    "                'regionCode': query.region_code,\n",
    "                'relevanceLanguage': query.language,\n",
    "                'order': query.order\n",
    "            }\n",
    "\n",
    "            # Add date filters if specified\n",
    "            if query.published_after:\n",
    "                search_params['publishedAfter'] = query.published_after.isoformat()\n",
    "            if query.published_before:\n",
    "                search_params['publishedBefore'] = query.published_before.isoformat()\n",
    "\n",
    "            # Execute search\n",
    "            search_response = self.youtube.search().list(**search_params).execute()\n",
    "\n",
    "            # Extract video IDs for detailed information\n",
    "            video_ids = [item['id']['videoId']\n",
    "                         for item in search_response['items']]\n",
    "\n",
    "            # Get detailed video information\n",
    "            videos = self._get_video_details(video_ids)\n",
    "\n",
    "            # Create search result\n",
    "            result = SearchResult(\n",
    "                query=query,\n",
    "                videos=videos,\n",
    "                total_results=search_response.get(\n",
    "                    'pageInfo', {}).get('totalResults', 0)\n",
    "            )\n",
    "\n",
    "            logger.info(f\"Found {len(videos)} videos for query: {query.query}\")\n",
    "            return result\n",
    "\n",
    "        except HttpError as e:\n",
    "            logger.error(f\"YouTube API error: {e}\")\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Unexpected error in video search: {e}\")\n",
    "            raise\n",
    "\n",
    "    def _get_video_details(self, video_ids: List[str]) -> List[VideoData]:\n",
    "        \"\"\"Get detailed information for specific video IDs\"\"\"\n",
    "        if not video_ids:\n",
    "            return []\n",
    "\n",
    "        try:\n",
    "            # YouTube API allows max 50 IDs per request\n",
    "            videos = []\n",
    "            for i in range(0, len(video_ids), 50):\n",
    "                batch_ids = video_ids[i:i+50]\n",
    "                batch_videos = self._fetch_video_batch(batch_ids)\n",
    "                videos.extend(batch_videos)\n",
    "\n",
    "            return videos\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error getting video details: {e}\")\n",
    "            return []\n",
    "\n",
    "    def _fetch_video_batch(self, video_ids: List[str]) -> List[VideoData]:\n",
    "        \"\"\"Fetch a batch of video details\"\"\"\n",
    "        try:\n",
    "            video_response = self.youtube.videos().list(\n",
    "                part='snippet,statistics,contentDetails',\n",
    "                id=','.join(video_ids)\n",
    "            ).execute()\n",
    "\n",
    "            videos = []\n",
    "            for item in video_response['items']:\n",
    "                video = self._parse_video_item(item)\n",
    "                if video:\n",
    "                    videos.append(video)\n",
    "\n",
    "            return videos\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error fetching video batch: {e}\")\n",
    "            return []\n",
    "\n",
    "    def _parse_video_item(self, item: Dict[str, Any]) -> Optional[VideoData]:\n",
    "        \"\"\"Parse YouTube API video item into VideoData model\"\"\"\n",
    "        try:\n",
    "            snippet = item['snippet']\n",
    "            statistics = item.get('statistics', {})\n",
    "            content_details = item.get('contentDetails', {})\n",
    "\n",
    "            # Parse duration\n",
    "            duration_str = content_details.get('duration', 'PT0S')\n",
    "            duration_seconds = int(isodate.parse_duration(\n",
    "                duration_str).total_seconds())\n",
    "\n",
    "            # Create video stats\n",
    "            stats = VideoStats(\n",
    "                view_count=int(statistics.get('viewCount', 0)),\n",
    "                like_count=int(statistics.get('likeCount', 0)),\n",
    "                comment_count=int(statistics.get('commentCount', 0)),\n",
    "                duration_seconds=duration_seconds\n",
    "            )\n",
    "\n",
    "            # Determine category\n",
    "            category = self._categorize_video(snippet.get(\n",
    "                'title', ''), snippet.get('description', ''))\n",
    "\n",
    "            # Parse published date\n",
    "            published_at = datetime.fromisoformat(\n",
    "                snippet['publishedAt'].replace('Z', '+00:00'))\n",
    "\n",
    "            # Create video data\n",
    "            video = VideoData(\n",
    "                video_id=item['id'],\n",
    "                title=snippet['title'],\n",
    "                description=snippet.get('description', ''),\n",
    "                channel_id=snippet['channelId'],\n",
    "                channel_title=snippet['channelTitle'],\n",
    "                published_at=published_at,\n",
    "                duration=duration_str,\n",
    "                category=category,\n",
    "                stats=stats,\n",
    "                tags=snippet.get('tags', []),\n",
    "                thumbnail_url=snippet.get(\n",
    "                    'thumbnails', {}).get('high', {}).get('url')\n",
    "            )\n",
    "\n",
    "            return video\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error parsing video item: {e}\")\n",
    "            return None\n",
    "\n",
    "    def _categorize_video(self, title: str, description: str) -> VideoCategory:\n",
    "        \"\"\"Categorize video based on title and description\"\"\"\n",
    "        content = (title + ' ' + description).lower()\n",
    "\n",
    "        # Simple keyword-based categorization\n",
    "        if any(word in content for word in ['tutorial', 'learn', 'education', 'course']):\n",
    "            return VideoCategory.EDUCATION\n",
    "        elif any(word in content for word in ['tech', 'programming', 'software', 'ai']):\n",
    "            return VideoCategory.TECHNOLOGY\n",
    "        elif any(word in content for word in ['game', 'gaming', 'play']):\n",
    "            return VideoCategory.GAMING\n",
    "        elif any(word in content for word in ['music', 'song', 'album']):\n",
    "            return VideoCategory.MUSIC\n",
    "        elif any(word in content for word in ['news', 'breaking', 'report']):\n",
    "            return VideoCategory.NEWS\n",
    "        elif any(word in content for word in ['sport', 'football', 'basketball']):\n",
    "            return VideoCategory.SPORTS\n",
    "        else:\n",
    "            return VideoCategory.OTHER\n",
    "\n",
    "    def get_channel_info(self, channel_id: str) -> Optional[ChannelData]:\n",
    "        \"\"\"Get detailed channel information\"\"\"\n",
    "        try:\n",
    "            channel_response = self.youtube.channels().list(\n",
    "                part='snippet,statistics',\n",
    "                id=channel_id\n",
    "            ).execute()\n",
    "\n",
    "            if not channel_response['items']:\n",
    "                return None\n",
    "\n",
    "            item = channel_response['items'][0]\n",
    "            snippet = item['snippet']\n",
    "            statistics = item.get('statistics', {})\n",
    "\n",
    "            # Parse creation date\n",
    "            created_at = None\n",
    "            if 'publishedAt' in snippet:\n",
    "                created_at = datetime.fromisoformat(\n",
    "                    snippet['publishedAt'].replace('Z', '+00:00'))\n",
    "\n",
    "            channel = ChannelData(\n",
    "                channel_id=channel_id,\n",
    "                title=snippet['title'],\n",
    "                description=snippet.get('description', ''),\n",
    "                subscriber_count=int(statistics.get('subscriberCount', 0)),\n",
    "                video_count=int(statistics.get('videoCount', 0)),\n",
    "                view_count=int(statistics.get('viewCount', 0)),\n",
    "                created_at=created_at,\n",
    "                thumbnail_url=snippet.get(\n",
    "                    'thumbnails', {}).get('high', {}).get('url')\n",
    "            )\n",
    "\n",
    "            return channel\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error getting channel info: {e}\")\n",
    "            return None\n",
    "\n",
    "    def get_trending_videos(self, region_code: str = 'US', max_results: int = 25) -> List[VideoData]:\n",
    "        \"\"\"Get trending videos for a specific region\"\"\"\n",
    "        try:\n",
    "            videos_response = self.youtube.videos().list(\n",
    "                part='snippet,statistics,contentDetails',\n",
    "                chart='mostPopular',\n",
    "                regionCode=region_code,\n",
    "                maxResults=min(max_results, 50)\n",
    "            ).execute()\n",
    "\n",
    "            videos = []\n",
    "            for item in videos_response['items']:\n",
    "                video = self._parse_video_item(item)\n",
    "                if video:\n",
    "                    videos.append(video)\n",
    "\n",
    "            return videos\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error getting trending videos: {e}\")\n",
    "            return []\n",
    "\n",
    "\n",
    "# Example usage and testing\n",
    "if __name__ == \"__main__\":\n",
    "    # Test YouTube service\n",
    "    try:\n",
    "        # Initialize service\n",
    "        youtube_service = YouTubeService()\n",
    "\n",
    "        # Test search\n",
    "        query = SearchQuery(\n",
    "            query=\"python tutorial\",\n",
    "            max_results=5,\n",
    "            order=\"viewCount\"\n",
    "        )\n",
    "\n",
    "        results = youtube_service.search_videos(query)\n",
    "        print(f\"Search Results: {len(results.videos)} videos found\")\n",
    "\n",
    "        for video in results.videos:\n",
    "            print(f\"- {video.title} ({video.stats.view_count:,} views)\")\n",
    "\n",
    "        print(\"\\nYouTube service test completed successfully!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"YouTube service test failed: {e}\")\n",
    "        print(\"Please check your YouTube API key in the .env file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b37b18a-84ee-4d95-9334-562bba19770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tools/video_search_tool.py - MCP Video Search Tool\n",
    "\n",
    "import logging\n",
    "from typing import Any, Dict, List\n",
    "from datetime import datetime\n",
    "from mcp import Tool\n",
    "\n",
    "from services.youtube_service import YouTubeService\n",
    "from models.youtube_models import SearchQuery\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class VideoSearchTool(Tool):\n",
    "    \"\"\"MCP tool for searching YouTube videos\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"search_videos\",\n",
    "            description=\"Search YouTube videos with detailed analysis and insights\",\n",
    "            inputSchema={\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Search query for YouTube videos\"\n",
    "                    },\n",
    "                    \"max_results\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"description\": \"Maximum number of results to return (default: 10)\",\n",
    "                        \"default\": 10\n",
    "                    },\n",
    "                    \"order\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Sort order: relevance, date, rating, viewCount\",\n",
    "                        \"default\": \"relevance\"\n",
    "                    },\n",
    "                    \"region_code\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Region code for localized results (default: US)\",\n",
    "                        \"default\": \"US\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"query\"]\n",
    "            }\n",
    "        )\n",
    "        self.youtube_service = YouTubeService()\n",
    "\n",
    "    async def call(self, arguments: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Execute video search\"\"\"\n",
    "        try:\n",
    "            # Extract parameters\n",
    "            query_text = arguments.get(\"query\", \"\")\n",
    "            max_results = min(arguments.get(\"max_results\", 10), 50)\n",
    "            order = arguments.get(\"order\", \"relevance\")\n",
    "            region_code = arguments.get(\"region_code\", \"US\")\n",
    "\n",
    "            logger.info(f\"Searching videos: {query_text}\")\n",
    "\n",
    "            # Create search query\n",
    "            search_query = SearchQuery(\n",
    "                query=query_text,\n",
    "                max_results=max_results,\n",
    "                order=order,\n",
    "                region_code=region_code\n",
    "            )\n",
    "\n",
    "            # Execute search\n",
    "            results = self.youtube_service.search_videos(search_query)\n",
    "\n",
    "            # Format results for MCP response\n",
    "            response = {\n",
    "                \"success\": True,\n",
    "                \"query\": query_text,\n",
    "                \"total_results\": results.total_results,\n",
    "                \"videos_found\": len(results.videos),\n",
    "                \"average_engagement\": f\"{results.average_engagement:.2%}\",\n",
    "                \"videos\": []\n",
    "            }\n",
    "\n",
    "            # Add video details\n",
    "            for video in results.videos:\n",
    "                video_data = {\n",
    "                    \"title\": video.title,\n",
    "                    \"channel\": video.channel_title,\n",
    "                    \"views\": video.stats.view_count,\n",
    "                    \"likes\": video.stats.like_count,\n",
    "                    \"comments\": video.stats.comment_count,\n",
    "                    \"engagement_rate\": f\"{video.stats.engagement_rate:.2%}\",\n",
    "                    \"published\": video.published_at.strftime(\"%Y-%m-%d\"),\n",
    "                    \"duration\": video.duration,\n",
    "                    \"category\": video.category.value,\n",
    "                    \"url\": f\"https://youtube.com/watch?v={video.video_id}\"\n",
    "                }\n",
    "                response[\"videos\"].append(video_data)\n",
    "\n",
    "            return response\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Video search error: {e}\")\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": str(e),\n",
    "                \"message\": \"Failed to search videos\"\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b89bab-9b80-4626-9e30-a33644e5f5f5",
   "metadata": {},
   "source": [
    "=======     Video #6  the Market Tool   ======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de17736b-f9b1-4461-9c98-76dca7450f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "need to uncomment the tool that we will be working with on mcp_server.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1280c18f-6a6f-4f6c-a14c-1b5f9c73951d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Real Estate Topics (Punta Cana)\n",
    "\n",
    "{\n",
    "  \"topic\": \"Punta Cana real estate market\",\n",
    "  \"timeframe_days\": 30,\n",
    "  \"sample_size\": 50\n",
    "}\n",
    "\n",
    "{\n",
    "  \"topic\": \"Punta Cana property investment\",\n",
    "  \"timeframe_days\": 60,\n",
    "  \"sample_size\": 40\n",
    "}\n",
    "\n",
    "{\n",
    "  \"topic\": \"Buying a vacation home in Punta Cana\",\n",
    "  \"timeframe_days\": 90,\n",
    "  \"sample_size\": 50\n",
    "}\n",
    "\n",
    "{\n",
    "  \"topic\": \"Punta Cana beachfront condos for sale\",\n",
    "  \"timeframe_days\": 30,\n",
    "  \"sample_size\": 25\n",
    "}\n",
    "{\n",
    "  \"topic\": \"Punta Cana real estate 2025 predictions\",\n",
    "  \"timeframe_days\": 180,\n",
    "  \"sample_size\": 20\n",
    "}\n",
    "\n",
    "\n",
    "Investment Topics (Punta Cana Business & Finance)\n",
    "\n",
    "{\n",
    "  \"topic\": \"Investing in Punta Cana\",\n",
    "  \"timeframe_days\": 30,\n",
    "  \"sample_size\": 50\n",
    "}\n",
    "\n",
    "{\n",
    "  \"topic\": \"Punta Cana rental property investment\",\n",
    "  \"timeframe_days\": 60,\n",
    "  \"sample_size\": 30\n",
    "}\n",
    "\n",
    "{\n",
    "  \"topic\": \"Punta Cana Airbnb income potential\",\n",
    "  \"timeframe_days\": 45,\n",
    "  \"sample_size\": 35\n",
    "}\n",
    "\n",
    "{\n",
    "  \"topic\": \"Punta Cana business opportunities\",\n",
    "  \"timeframe_days\": 90,\n",
    "  \"sample_size\": 40\n",
    "}\n",
    "\n",
    "{\n",
    "  \"topic\": \"Punta Cana luxury resort investments\",\n",
    "  \"timeframe_days\": 180,\n",
    "  \"sample_size\": 25\n",
    "}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440437f5-d008-46c1-9290-69003af55982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tools/market_analysis_tool.py - Market Analysis Tool\n",
    "\n",
    "import logging\n",
    "from typing import Any, Dict, List\n",
    "from datetime import datetime, timedelta\n",
    "from mcp import Tool\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "\n",
    "from services.youtube_service import YouTubeService\n",
    "from models.youtube_models import SearchQuery\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class MarketAnalysisTool(Tool):\n",
    "    \"\"\"MCP tool for YouTube market analysis and trends\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"analyze_market\",\n",
    "            description=\"Analyze YouTube market trends and competition for specific topics\",\n",
    "            inputSchema={\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"topic\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Topic or niche to analyze\"\n",
    "                    },\n",
    "                    \"timeframe_days\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"description\": \"Analyze videos from last N days (default: 30)\",\n",
    "                        \"default\": 30\n",
    "                    },\n",
    "                    \"sample_size\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"description\": \"Number of videos to analyze (default: 50)\",\n",
    "                        \"default\": 50\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"topic\"]\n",
    "            }\n",
    "        )\n",
    "        self.youtube_service = YouTubeService()\n",
    "\n",
    "    async def call(self, arguments: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Execute market analysis\"\"\"\n",
    "        try:\n",
    "            topic = arguments.get(\"topic\", \"\")\n",
    "            timeframe_days = arguments.get(\"timeframe_days\", 30)\n",
    "            sample_size = min(arguments.get(\"sample_size\", 50), 100)\n",
    "\n",
    "            logger.info(f\"Analyzing market for topic: {topic}\")\n",
    "\n",
    "            # Search for recent videos\n",
    "            published_after = datetime.now() - timedelta(days=timeframe_days)\n",
    "            search_query = SearchQuery(\n",
    "                query=topic,\n",
    "                max_results=sample_size,\n",
    "                published_after=published_after,\n",
    "                order=\"viewCount\"\n",
    "            )\n",
    "\n",
    "            results = self.youtube_service.search_videos(search_query)\n",
    "\n",
    "            if not results.videos:\n",
    "                return {\n",
    "                    \"success\": False,\n",
    "                    \"message\": f\"No videos found for topic: {topic}\"\n",
    "                }\n",
    "\n",
    "            # Analyze market metrics\n",
    "            analysis = self._analyze_market_data(results.videos, topic)\n",
    "\n",
    "            return {\n",
    "                \"success\": True,\n",
    "                \"topic\": topic,\n",
    "                \"timeframe_days\": timeframe_days,\n",
    "                \"videos_analyzed\": len(results.videos),\n",
    "                \"analysis\": analysis\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Market analysis error: {e}\")\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": str(e),\n",
    "                \"message\": \"Failed to analyze market\"\n",
    "            }\n",
    "\n",
    "    def _analyze_market_data(self, videos, topic):\n",
    "        \"\"\"Analyze market data and generate insights\"\"\"\n",
    "        # Convert to DataFrame for analysis\n",
    "        data = []\n",
    "        for video in videos:\n",
    "            data.append({\n",
    "                'title': video.title,\n",
    "                'views': video.stats.view_count,\n",
    "                'likes': video.stats.like_count,\n",
    "                'comments': video.stats.comment_count,\n",
    "                'engagement_rate': video.stats.engagement_rate,\n",
    "                'channel': video.channel_title,\n",
    "                'published': video.published_at,\n",
    "                'duration_seconds': video.stats.duration_seconds\n",
    "            })\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        # Calculate market metrics\n",
    "        total_views = df['views'].sum()\n",
    "        avg_views = df['views'].mean()\n",
    "        avg_engagement = df['engagement_rate'].mean()\n",
    "\n",
    "        # Find top performers\n",
    "        top_videos = df.nlargest(5, 'views')[\n",
    "            ['title', 'views', 'channel']].to_dict('records')\n",
    "\n",
    "        # Channel analysis\n",
    "        channel_performance = df.groupby('channel').agg({\n",
    "            'views': ['sum', 'mean', 'count'],\n",
    "            'engagement_rate': 'mean'\n",
    "        }).round(2)\n",
    "\n",
    "        top_channels = channel_performance.nlargest(5, ('views', 'sum'))\n",
    "\n",
    "        # Sentiment analysis on titles\n",
    "        sentiments = [\n",
    "            TextBlob(title).sentiment.polarity for title in df['title']]\n",
    "        avg_sentiment = sum(sentiments) / len(sentiments) if sentiments else 0\n",
    "\n",
    "        # Competition analysis\n",
    "        unique_channels = df['channel'].nunique()\n",
    "        competition_level = \"High\" if unique_channels > 30 else \"Medium\" if unique_channels > 15 else \"Low\"\n",
    "\n",
    "        return {\n",
    "            \"market_overview\": {\n",
    "                \"total_views\": int(total_views),\n",
    "                \"average_views\": int(avg_views),\n",
    "                \"average_engagement_rate\": f\"{avg_engagement:.2%}\",\n",
    "                \"unique_creators\": unique_channels,\n",
    "                \"competition_level\": competition_level,\n",
    "                \"market_sentiment\": f\"{avg_sentiment:.2f}\"\n",
    "            },\n",
    "            \"top_performing_videos\": top_videos,\n",
    "            \"top_channels\": [\n",
    "                {\n",
    "                    \"channel\": idx,\n",
    "                    \"total_views\": int(row[('views', 'sum')]),\n",
    "                    \"avg_views\": int(row[('views', 'mean')]),\n",
    "                    \"video_count\": int(row[('views', 'count')]),\n",
    "                    \"avg_engagement\": f\"{row[('engagement_rate', 'mean')]:.2%}\"\n",
    "                }\n",
    "                for idx, row in top_channels.head(5).iterrows()\n",
    "            ],\n",
    "            \"insights\": self._generate_market_insights(df, topic, competition_level)\n",
    "        }\n",
    "\n",
    "    def _generate_market_insights(self, df, topic, competition_level):\n",
    "        \"\"\"Generate actionable market insights\"\"\"\n",
    "        insights = []\n",
    "\n",
    "        # View distribution insight\n",
    "        views_std = df['views'].std()\n",
    "        views_mean = df['views'].mean()\n",
    "        if views_std > views_mean:\n",
    "            insights.append(\n",
    "                \"High variance in video performance - opportunity for viral content\")\n",
    "\n",
    "        # Engagement insight\n",
    "        high_engagement = df[df['engagement_rate'] > 0.05]\n",
    "        if len(high_engagement) > 0:\n",
    "            avg_duration = high_engagement['duration_seconds'].mean()\n",
    "            insights.append(\n",
    "                f\"High-engagement videos average {int(avg_duration/60)} minutes duration\")\n",
    "\n",
    "        # Competition insight\n",
    "        if competition_level == \"Low\":\n",
    "            insights.append(\n",
    "                \"Low competition - good opportunity to establish authority\")\n",
    "        elif competition_level == \"High\":\n",
    "            insights.append(\n",
    "                \"High competition - focus on unique angle or underserved subtopics\")\n",
    "\n",
    "        # Upload timing insight\n",
    "        recent_videos = df[df['published'] > (\n",
    "            datetime.now() - timedelta(days=7))]\n",
    "        if len(recent_videos) > len(df) * 0.3:\n",
    "            insights.append(\n",
    "                \"High recent activity - trending topic with immediate opportunity\")\n",
    "\n",
    "        return insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33680062-914a-4b08-a1c1-517fdf98dfe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687e1d8c-b211-40a9-bfec-c03e6fc2d2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyproject.toml\n",
    "[build-system]\n",
    "requires = [\"setuptools>=61.0\", \"wheel\"]\n",
    "build-backend = \"setuptools.build_meta\"\n",
    "\n",
    "[project]\n",
    "name = \"youtube-intelligence-mcp\"\n",
    "version = \"1.0.0\"\n",
    "description = \"YouTube Intelligence MCP Server for AI-powered video analysis\"\n",
    "authors = [{ name = \"Francesco Piscani's YouTube Intelligence AI Platform Team\" }]\n",
    "license = { text = \"MIT\" }\n",
    "readme = \"README.md\"\n",
    "requires-python = \">=3.9\"\n",
    "classifiers = [\n",
    "    \"Development Status :: 4 - Beta\",\n",
    "    \"Intended Audience :: Developers\",\n",
    "    \"License :: OSI Approved :: MIT License\",\n",
    "    \"Programming Language :: Python :: 3\",\n",
    "    \"Programming Language :: Python :: 3.9\",\n",
    "    \"Programming Language :: Python :: 3.10\",\n",
    "    \"Programming Language :: Python :: 3.11\",\n",
    "]\n",
    "dependencies = [\n",
    "    \"mcp>=0.9.0\",\n",
    "    \"google-api-python-client==2.108.0\",\n",
    "    \"pandas==2.1.3\",\n",
    "    \"numpy==1.24.3\",\n",
    "    \"nltk==3.8.1\",\n",
    "    \"textblob==0.17.1\",\n",
    "    \"anthropic==0.7.7\",\n",
    "    \"firebase-admin==6.2.0\",\n",
    "    \"python-dotenv==1.0.0\",\n",
    "    \"pydantic==2.5.0\",\n",
    "    \"aiofiles==23.2.1\",\n",
    "    \"psutil==5.9.6\",\n",
    "]\n",
    "\n",
    "[project.scripts]\n",
    "youtube-intelligence-mcp = \"server.__main__:main\"\n",
    "\n",
    "[tool.setuptools.packages.find]\n",
    "include = [\"*\"]\n",
    "exclude = [\"tests*\", \"*.ipynb_checkpoints*\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab6e9ce-dc7f-417a-a98e-4583b834c296",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
